{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76ee8256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F #?? \n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d2310a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This should be in another place, but I couldnt figure out how to import from another notebook\n",
    "def initialize_weights(*models):\n",
    "    for model in models:\n",
    "        for module in model.modules():\n",
    "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "                nn.init.kaiming_normal(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    module.bias.data.zero_()\n",
    "            elif isinstance(module, nn.BatchNorm2d):\n",
    "                module.weight.data.fill_(1)\n",
    "                module.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1384794",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _EncoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(model, input_channels, output_channels, dropout=False, polling=True, bn=False):\n",
    "        #class initialization with inputs model, the input and output channels, and choices on whether to dropout, poll, or use batch normalization\n",
    "        super(_EncoderBlock, model).__init__() #Takes initialization values from torch library\n",
    "        layers = [ #Set layers as two sets of: Convolution, Normalization (Batch or Group), GELU activation\n",
    "            nn.Conv2d(input_channels, output_channels, kernel_size=3, padding=1, padding_mode='reflect'),\n",
    "            nn.BatchNorm2d(output_channels) if bn else nn.GroupNorm(32, output_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(output_channels, output_channels, kernel_size=3, padding=1, padding_mode='reflect'),\n",
    "            nn.BatchNorm2d(output_channels) if bn else nn.GroupNorm(32, output_channels),\n",
    "            nn.GELU(),\n",
    "        ]\n",
    "        \n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout()) #Add dropout layer to the list if requested\n",
    "            \n",
    "        model.encode = nn.Sequential(*layers) #Set the encode atribute as the actual build of the model\n",
    "        model.pool = None\n",
    "        if polling:\n",
    "            model.pool = nn.MaxPool2d(kernel_size=2, stride=2) #If pooling is requested, create an atribute for it\n",
    "        \n",
    "    def forward(model,x): #This function is called by pytorch automatically, and is the actual \"running\" part of the class\n",
    "        if model.pool is not None:\n",
    "            x = model.pool(x) #Does pooling if previously requested\n",
    "        return model.encode(x) #Returns the encoded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9db6cdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _DecoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(model, input_channels, middle_channels, output_channels, bn=False):\n",
    "        super(_DecoderBlock, model).__init__()\n",
    "        layers = [ #Same layers as above. It will later be used backward to \"decode\"\n",
    "            nn.Conv2d(input_channels, middle_channels, kernel_size=3, padding=1, padding_mode='reflect'),\n",
    "            nn.BatchNorm2d(middle_channels) if bn else nn.GroupNorm(32, middle_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(middle_channels, output_channels, kernel_size=3, padding=1, padding_mode='reflect'),\n",
    "            nn.BatchNorm2d(output_channels) if bn else nn.GroupNorm(32, output_channels),\n",
    "            nn.GELU(),\n",
    "        ]\n",
    "        \n",
    "        #There is no pooling for the decoding steps\n",
    "        \n",
    "        model.decode = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(model, x):\n",
    "        return model.decode(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b83ea2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    \n",
    "    def __init__(model, classes, input_channels=3, bn=False):\n",
    "        #Initializing the full UNet architecture. bn and input_channels are set, but put as inputs to make it easy to change\n",
    "        super(UNet, model).__init__()\n",
    "        model.enc1 = _EncoderBlock(input_channels, 64, polling=False, bn=bn)\n",
    "        model.enc2 = _EncoderBlock(64, 128, bn=bn)\n",
    "        model.enc3 = _EncoderBlock(128, 256, bn=bn)\n",
    "        model.enc4 = _EncoderBlock(256, 512, bn=bn)\n",
    "        \n",
    "        model.polling = nn.AvgPool2d(kernel_size=2, stride=2)        \n",
    "        model.center = _DecoderBlock(512, 1024, 512, bn=bn)\n",
    "        #Pool and centering before transitioning between encoding and decoding. Similar to \"flatten\"\n",
    "        \n",
    "        model.dec4 = _DecoderBlock(1024, 512, 256, bn=bn)\n",
    "        model.dec3 = _DecoderBlock(512, 256, 128, bn=bn)\n",
    "        model.dec2 = _DecoderBlock(256, 128, 64, bn=bn)\n",
    "        model.dec1 = nn.Sequential( #For the last convolution set, we remove padding and change the kernel size\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1, padding_mode='reflect'),\n",
    "            nn.BatchNorm2d(64) if bn else nn.GroupNorm(32, 64),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=1, padding=0),\n",
    "            nn.BatchNorm2d(64) if bn else nn.GroupNorm(32, 64),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "        \n",
    "        model.final = nn.Conv2d(64, classes, kernel_size=1) #One last convolution\n",
    "        initialize_weights(model) #initialize weights for our model\n",
    "        \n",
    "    def forward(model, x): #Actually run through the model for some input\n",
    "        enc1 = model.enc1(x)\n",
    "        enc2 = model.enc2(enc1)\n",
    "        enc3 = model.enc3(enc2)\n",
    "        enc4 = model.enc4(enc3)\n",
    "        center = model.center(model.polling(enc4)) #This is the \"flattening\" step\n",
    "        dec4 = model.dec4(torch.cat([F.interpolate(center, enc4.size()[-2:], align_corners=False, mode='bilinear'), enc4], 1))\n",
    "        dec3 = model.dec3(torch.cat([F.interpolate(dec4, enc3.size()[-2:], align_corners=False, mode='bilinear'), enc3], 1))\n",
    "        dec2 = model.dec2(torch.cat([F.interpolate(dec3, enc2.size()[-2:], align_corners=False, mode='bilinear'), enc2], 1))\n",
    "        dec1 = model.dec1(torch.cat([F.interpolate(dec2, enc1.size()[-2:], align_corners=False, mode='bilinear'), enc1], 1))\n",
    "        #There is more required for the decoding as we need to take the previous step and merge it with the encoding output\n",
    "        #It first interpolates decN to the size of encN, then concatenates the two together, then runs the decoder block\n",
    "        \n",
    "        final = model.final(dec1)\n",
    "        \n",
    "        return final    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e2430b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2161/987690111.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(module.weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet(\n",
      "  (enc1): _EncoderBlock(\n",
      "    (encode): Sequential(\n",
      "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "      (2): GELU()\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (4): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "      (5): GELU()\n",
      "    )\n",
      "  )\n",
      "  (enc2): _EncoderBlock(\n",
      "    (encode): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      (2): GELU()\n",
      "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (4): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      (5): GELU()\n",
      "    )\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (enc3): _EncoderBlock(\n",
      "    (encode): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "      (2): GELU()\n",
      "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (4): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "      (5): GELU()\n",
      "    )\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (enc4): _EncoderBlock(\n",
      "    (encode): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (2): GELU()\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (4): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (5): GELU()\n",
      "    )\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (polling): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (center): _DecoderBlock(\n",
      "    (decode): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
      "      (2): GELU()\n",
      "      (3): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (4): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (5): GELU()\n",
      "    )\n",
      "  )\n",
      "  (dec4): _DecoderBlock(\n",
      "    (decode): Sequential(\n",
      "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (2): GELU()\n",
      "      (3): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (4): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "      (5): GELU()\n",
      "    )\n",
      "  )\n",
      "  (dec3): _DecoderBlock(\n",
      "    (decode): Sequential(\n",
      "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "      (2): GELU()\n",
      "      (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (4): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      (5): GELU()\n",
      "    )\n",
      "  )\n",
      "  (dec2): _DecoderBlock(\n",
      "    (decode): Sequential(\n",
      "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      (2): GELU()\n",
      "      (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (4): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "      (5): GELU()\n",
      "    )\n",
      "  )\n",
      "  (dec1): Sequential(\n",
      "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "    (1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (2): GELU()\n",
      "    (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (4): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (5): GELU()\n",
      "  )\n",
      "  (final): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 200, 200])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    model = UNet(input_channels=1, classes=1)\n",
    "    print(model)\n",
    "    x = torch.randn(1, 1, 200, 200)\n",
    "    with torch.no_grad():\n",
    "        final = model(x)\n",
    "        print(final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86d6916",
   "metadata": {},
   "source": [
    "Things to do:\n",
    "\n",
    "Remove dropout. It doesnt seem to be used in the model and was probably just a carryover from their testing. Need to see if its used anywhere else. \n",
    "\n",
    "Figure out how to import functions from other directories. The initialize_weights function should be imported from the utils folder instead of in here. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
